{"cells":[{"cell_type":"markdown","source":["# Notebook on Keras/Tensorflow \"Deep\" NN Modeling for Images\n","\n","The notebook is from Dane Morgan's class again, but also with almost all materials taken from others (see below.) We will build a standard deep NN for the American Sign Language dataset (images of hands making letters in [American Sign Language](http://www.asl.gs/)). Note that this NN is not convolutional and not very \"deep\", but has mulitple layers and many parameters.\n","* Most taken from [Nvidia Deep Learning course](https://www.nvidia.com/en-us/training/).\n","\n","Learning goal(s):\n","* Be able to build a simple deep learning Neural Network and train and aseess it using Keras/Tensorflow.\n","* Prepare image data for training.\n","Create and compile a simple model for image classification.\n","* Train an image classification model and observe the results.\n","\n","\n"],"metadata":{"id":"FZEEsw6CaFyG"}},{"cell_type":"markdown","source":["# Colab setup"],"metadata":{"id":"ON6GZAQIuUy-"}},{"cell_type":"markdown","source":["## GPUs\n","This lab is much faster on GPUs/TPUs. Using GPUs or TPUs by doing the following (might not be always available):\n","* Enabling GPU. To enable GPU in your notebook, (i) Edit/Notebook Settings, or (ii) select the following menu options âˆ’ Runtime / Change runtime type. See which works.\n","* Testing for GPU. You can easily check if the GPU is enabled by executing the following code:"],"metadata":{"id":"WxvIWGP3uOvn"}},{"cell_type":"code","source":["# Test if running GPU\n","import tensorflow as tf\n","tf.test.gpu_device_name()"],"metadata":{"id":"RZcVvi0nkdXW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"9qf47v1fLhfI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here, modify the path where you saved this notebook and the associated lab files on your Google drive, if different from below."],"metadata":{"id":"6gO8ou2I-5XE"}},{"cell_type":"code","source":["path = '/content/drive/MyDrive/Path to Lab3/Lab3'\n","#path = '/content/drive/MyDrive/Online Filed/Dane Morgan Mixed Sharing/Projects/Courses/MSE803 F22/Dane student view/MSE803_Lab1'"],"metadata":{"id":"7kM0EyBe-3eD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check the path name is assigned correctly."],"metadata":{"id":"xlqasneGCLyp"}},{"cell_type":"code","source":["!echo $path\n","import os\n","os.path.isdir(path)\n"],"metadata":{"id":"JRmONpl2CRhP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This is needed so can import packages from a different path than standard libraries\n","import sys\n","sys.path.append(path)"],"metadata":{"id":"MHR8oNCU-xFc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Some useful functions"],"metadata":{"id":"vsndMdObuExZ"}},{"cell_type":"code","source":["# This plots scores for training and validation data vs. epoch.\n","def err_plot(acc, val_acc, loss, val_loss):\n","  import matplotlib.pyplot as plt\n","\n","  epochs = range(1, len(acc) + 1)\n","\n","  plt.plot(epochs, acc, 'bo', label='Training acc')\n","  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","  plt.title('Training and validation accuracy')\n","  plt.legend()\n","\n","  plt.figure()\n","\n","  plt.plot(epochs, loss, 'bo', label='Training loss')\n","  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","  plt.title('Training and validation loss')\n","  plt.legend()\n","\n","  plt.show()\n","\n"],"metadata":{"id":"Ar_pFew4uIeZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RATvqc_Jk6Vl"},"source":["# Setting up the Data\n","This dataset is not available via Keras in the same way that some data sets are (e.g., MNIST). This dataset is available from the website [Kaggle](http://www.kaggle.com), which is a fantastic place to find datasets and other deep learning resources. In addition to providing resources like datasets and \"kernels\" that are like these notebooks, Kaggle hosts competitions that you can take part in, competing with others in training highly accurate models.\n","\n","If you're looking to practice or see examples of many deep learning projects, Kaggle is a great site to visit."]},{"cell_type":"markdown","metadata":{"id":"w4dg1FXik6Vi"},"source":["We will be learning to classify images into letters in the American Sign Language Alphabet (ASL). The [ASL alphabet](http://www.asl.gs/) contains 26 letters. Two of those letters (j and z) require movement, so they are not included in the training dataset. We display the images below.\n","\n","Note: You need to download figures (see Hw3 description) and put them into the \"images\" directory before you can run these \"display\" cells."]},{"cell_type":"code","source":["from IPython.display import Image\n","filename = os.path.join(path, 'images/asl.png')\n","print('Loading image from: ',filename)\n","display(Image(filename, width=600))"],"metadata":{"id":"RDkA8SeZo1Xt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jA4WT16Xk6Vn"},"source":["## Reading in the Data\n","Use Pandas DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NEvJOe_Qk6Vr"},"outputs":[],"source":["import pandas as pd\n","train_df = pd.read_csv(os.path.join(path, 'sign_mnist_train.csv'))\n","valid_df = pd.read_csv(os.path.join(path, 'sign_mnist_valid.csv'))"]},{"cell_type":"markdown","metadata":{"id":"S-jtubEvk6Vs"},"source":["## Exploring the Data"]},{"cell_type":"markdown","metadata":{"id":"dnNHdaaHk6Vs"},"source":["Let's take a look at our data. We can use the [head](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) method to print the first few rows of the DataFrame. Each row is an image which has a `label` column, and also, 784 values representing each pixel value in the image, just like with the MNIST dataset. Note that the labels currently are numerical values, not letters of the alphabet:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VbGrZLGZk6Vt"},"outputs":[],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"AAoLDW3Sk6Vt"},"source":["## Extracting the Labels"]},{"cell_type":"markdown","metadata":{"id":"TDuU0ss2k6Vt"},"source":["We would like to store our training and validation labels in `y_train` and `y_valid` variables. Here we create those variables and then delete the labels from our original dataframes, where they are no longer needed:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_kSoOPd8k6Vu"},"outputs":[],"source":["y_train = train_df['label']\n","y_valid = valid_df['label']\n","del train_df['label']\n","del valid_df['label']"]},{"cell_type":"markdown","metadata":{"id":"FjX0u0pBk6Vu"},"source":["## Extracting the Images"]},{"cell_type":"markdown","metadata":{"id":"hGAnd3w-k6Vu"},"source":["We would like to store our training and validation images in `x_train` and `x_valid` variables. Here we create those variables:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIwmjHBjk6Vv"},"outputs":[],"source":["x_train = train_df.values\n","x_valid = valid_df.values"]},{"cell_type":"markdown","metadata":{"id":"79aX748Pk6Vv"},"source":["## Summarizing the Training and Validation Data"]},{"cell_type":"markdown","metadata":{"id":"14fdI5Sdk6Vv"},"source":["We now have 27,455 images with 784 pixels each for training..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_h0BMWCSk6Vw"},"outputs":[],"source":["x_train.shape"]},{"cell_type":"markdown","metadata":{"id":"rPG8k0-kk6Vw"},"source":["...as well as their corresponding labels:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GdKCj_xbk6Vw"},"outputs":[],"source":["y_train.shape"]},{"cell_type":"markdown","metadata":{"id":"8vtB5cydk6Vx"},"source":["For validation, we have 7,172 images..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9uG9E8Vjk6Vx"},"outputs":[],"source":["x_valid.shape"]},{"cell_type":"markdown","metadata":{"id":"XFH3_Tmrk6Vx"},"source":["...and their corresponding labels:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gX0AWF3Ak6Vy"},"outputs":[],"source":["y_valid.shape"]},{"cell_type":"markdown","metadata":{"id":"PhZbRURlk6Vy"},"source":["## Visualizing the Data"]},{"cell_type":"markdown","metadata":{"id":"GSs4asnIk6Vy"},"source":["To visualize the images, we will again use the matplotlib library. We don't need to worry about the details of this visualization, but if interested, you can learn more about [matplotlib](https://matplotlib.org/) at a later time.\n","\n","Note that we'll have to reshape the data from its current 1D shape of 784 pixels, to a 2D shape of 28x28 pixels to make sense of the image:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZOP4ECqk6Vz"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.figure(figsize=(40,40))\n","\n","num_images = 20\n","for i in range(num_images):\n","    row = x_train[i]\n","    label = y_train[i]\n","\n","    image = row.reshape(28,28)\n","    plt.subplot(1, num_images, i+1)\n","    plt.title(label, fontdict={'fontsize': 30})\n","    plt.axis('off')\n","    plt.imshow(image, cmap='gray')"]},{"cell_type":"markdown","metadata":{"id":"_kDzUM5Vk6V0"},"source":["# Preprocess the Image Data"]},{"cell_type":"markdown","source":["## Normalize the Image Data"],"metadata":{"id":"PBL7_eyhdecf"}},{"cell_type":"markdown","metadata":{"id":"s0iQYUmAk6V0"},"source":["We are going to normalize the image data, meaning that their pixel values, instead of being between 0 and 255 as they are currently:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLYMwAYbk6V1"},"outputs":[],"source":["x_train.min()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mi3yb0iLk6V1"},"outputs":[],"source":["x_train.max()"]},{"cell_type":"markdown","metadata":{"id":"AqmhXXntk6V1"},"source":["...should be floating point values between 0 and 1. Use the following cell to work. If you get stuck, look at the solution below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xxB_NfrSk6V1"},"outputs":[],"source":["x_train = x_train / 255\n","x_valid = x_valid / 255"]},{"cell_type":"markdown","metadata":{"id":"zWKwjPkbk6V3"},"source":["## Categorize the Labels"]},{"cell_type":"markdown","metadata":{"id":"R2NELK51k6V3"},"source":["We are going to categorically (one-hot) encode the labels. We can use the [keras.utils.to_categorical](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) method to accomplish this by passing it the values to encode, and, the number of categories to encode it into."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M56wIJDck6V4"},"outputs":[],"source":["import tensorflow.keras as keras\n","num_classes = 24\n","if not y_train.shape[-1] == 24:  # Avoid running multiple times\n","    y_train = keras.utils.to_categorical(y_train, num_classes)\n","    y_valid = keras.utils.to_categorical(y_valid, num_classes)"]},{"cell_type":"markdown","source":["# Build and Fit the Model"],"metadata":{"id":"YftulcUYdrR9"}},{"cell_type":"markdown","metadata":{"id":"-lcYisvyk6V6"},"source":["## Build the Model"]},{"cell_type":"markdown","metadata":{"id":"Eipn-Smkk6V6"},"source":["The data is all prepared, we have normalized images for training and validation, as well as categorically encoded labels for training and validation.\n","\n","For this exercise we are going to build a sequential model that:\n","* Has a dense input layer. This layer should contain 512 neurons, use the `relu` activation function, and expect input images with a shape of `(784,)`.\n","* Has a dense output layer with neurons equal to the number of classes, using the `softmax` activation function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YWkq-Vrxk6V7"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","model = Sequential()\n","model.add(Dense(units = 512, activation='relu', input_shape=(784,)))\n","model.add(Dense(units = num_classes, activation='softmax'))"]},{"cell_type":"markdown","metadata":{"id":"5ckRTKhdk6V9"},"source":["## Summarizing the Model"]},{"cell_type":"markdown","metadata":{"id":"wz2lrBV_k6V-"},"source":["Run the cell below to summarize the model you just created:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7hr68OwSk6V-"},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"ZNcNw6Xwk6V-"},"source":["## Compiling the Model"]},{"cell_type":"markdown","metadata":{"id":"hnBuieDFk6V-"},"source":["We'll [compile](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile) our model with a loss function of [categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) to reflect the fact that we want to fit into one of many categories, and measuring the accuracy of our model as it is fit:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qEmmwZb8k6V_"},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"cpmt2g6bk6V_"},"source":["## Train the Model"]},{"cell_type":"markdown","metadata":{"id":"PurvsbsMk6V_"},"source":["Use the model's `fit` method to train it for 20 epochs using the training and validation images and labels created above (~2 min)."]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"id":"b8xDkRLHk6WA"},"outputs":[],"source":["hist=model.fit(x_train, y_train, epochs=20, verbose=1, validation_data=(x_valid, y_valid))"]},{"cell_type":"markdown","source":["## Analyze Model Results"],"metadata":{"id":"BE1o2IZqv2-j"}},{"cell_type":"markdown","source":["Key data to assess include how the loss function evolves during learning with each epoch to see if we are actually doing any training.  Also the accuracy (number of correct predictions divided by the total number of predictions) is a good metric to see how well our model is doing.  We usually want results for training and validation data."],"metadata":{"id":"OHYe5AJPiBvR"}},{"cell_type":"code","source":["# See what data we have saved in history from model run\n","print(hist.history.keys())"],"metadata":{"id":"SbulC51ZjGlc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot accuracy and loss\n","acc = hist.history['accuracy']\n","val_acc = hist.history['val_accuracy']\n","loss = hist.history['loss']\n","val_loss = hist.history['val_loss']\n","\n","err_plot(acc,val_acc,loss,val_loss)"],"metadata":{"id":"1ut1mKZlhFFn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Output top accuracy in validation data\n","max_acc = max(hist.history['val_accuracy'])\n","maxacc_index = hist.history['val_accuracy'].index(max_acc)+1\n","print(\"Best validation accuracy during run was: %1.2f on epoch %i\"\n","      % (max_acc, maxacc_index))"],"metadata":{"id":"y1CP3ez-k0Qx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y0pdhaLgk6WA"},"source":["## Discussion: What happened?"]},{"cell_type":"markdown","metadata":{"id":"6OOPn4cfk6WB"},"source":["We can see that the training accuracy got to a fairly high level, but the validation accuracy was not as high. What happened here?\n","\n","This is an example of the model learning to categorize the training data, but performing poorly against new data that it has not been trained on. Essentially, it is memorizing the dataset, but not gaining a robust and general understanding of the problem, which means *overfitting*."]},{"cell_type":"markdown","metadata":{"id":"3xFYTxF8k6WB"},"source":["# Summary"]},{"cell_type":"markdown","metadata":{"id":"7DYZEsN4k6WB"},"source":["In this section you built your own neural network to perform image classification that is quite accurate. Congrats!\n","\n","At this point we should be getting somewhat familiar with the process of loading data (incuding labels), preparing it, creating a model, and then training the model with prepared data."]},{"cell_type":"markdown","source":["# Question 1\n","Add another dense layer of 512 nodes and retrain and so you can compare to the best validation accuracy to what you got with the initial architecture above.  Provide a similar plot of train and validation accuracy and give value of best value from this NN vs. above result"],"metadata":{"id":"LOL3YgDHw8rY"}},{"cell_type":"markdown","source":["Answer:"],"metadata":{"id":"WbEpOINYxD4d"}},{"cell_type":"code","source":[],"metadata":{"id":"HzkzjfOr0VOI"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}